# README

## 课程推荐

### CS229: Machine Learning

地址：http://cs229.stanford.edu/syllabus.html

简介：吴恩达教授讲授，是一门研究生课程，更偏重数学理论，不满足于调包而想深入理解算法本质，或者有志于从事机器学习理论研究的同学可以学习这门课程。课程网站上提供了所有的课程notes，写得非常专业且理论，需要一定的数学功底。

### 动手学深度学习

地址：https://zh-v2.d2l.ai/

简介：亚马逊首席科学家李沐老师主编的面向中文读者的能运行、可讨论的深度学习教科书，含NumPy/MXNet、PyTorch 和TensorFlow 实现，而且沐神B站有号，投稿了全套中文讲解视频，另外还有个持续更新的论文讲解栏目，也很值得关注。

### 台湾国立大学：李宏毅机器学习

地址：https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.php

简介：李宏毅老师是台湾国立大学的教授，其风趣幽默的授课风格深受大家喜爱，并且尤其喜欢在PPT中插入宝可梦等动漫元素，是个非常可爱的老师。其作业一共包含15个lab，分别是Regression、Classification、CNN、Self-Attention、Transformer、GAN、BERT、Anomaly Detection、Explainable AI、Attack、Adaptation、 RL、Compression、Life-Long  Learning以及Meta  Learning。可谓是包罗万象，能让学生对于深度学习的绝大多数领域都有一定了解，从而可以进一步选择想要深入的方向进行学习。

### CS224n: Natural Language Processing

地址：http://web.stanford.edu/class/cs224n/index.html

简介：Stanford的NLP入门课程，由自然语言处理领域的巨佬Chris Manning领衔教授（word2vec算法的开创者）。内容覆盖了词向量、RNN、LSTM、Seq2Seq模型、机器翻译、注意力机制、Transformer等等NLP领域的核心知识点。5个编程作业难度循序渐进，分别是词向量、word2vec算法、Dependency parsing、机器翻译以及Transformer的fine-tune。

## 项目推荐

### 基于transformers的自然语言处理(NLP)入门

地址：https://github.com/datawhalechina/learn-nlp-with-transformers

简介：开源组织DataWhale发起的组队学习项目，面向的对象是：NLP初学者、transformer初学者；有一定的python、pytorch编程基础；对前沿的transformer模型感兴趣；了解和知道简单的深度学习模型。项目希望结合形象生动的原理讲解和多个动手实践项目，帮助初学者快速入门深度学习时代的NLP。

### NLP-Beginner：自然语言处理入门练习

地址：https://github.com/FudanNLP/nlp-beginner

简介：复旦大学邱锡鹏教授指导的实验室的入门练习，包含基于机器学习的文本分类、基于深度学习的文本分类、基于注意力机制的文本匹配、基于LSTM+CRF的序列标注、基于神经网络的语言模型五个任务。

## 书籍推荐

《统计学习方法》-清华大学出版社-李航

《机器学习》-清华大学出版社-周志华

《自然语言处理：基于预训练模型的方法》-电子工业出版社-车万翔

